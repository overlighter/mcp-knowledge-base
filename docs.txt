so in my code i want to create  script that would fetch two different json from fund and allocation  save it in two file and write an hash for each so in my next fetch i would compare if there are not same then i would replace it with the new file.

this is my rough code i wrote 
// testAirtable.js
import axios from "axios";
import dotenv from "dotenv";
import fs from "fs";
dotenv.config();

const AIRTABLE_PAT = process.env.AIRTABLE_PAT;
const BASE_ID = "appMXDULPdtP3RsYT";

// ‚úÖ Tables to export
const TABLES = [
  { name: "Funds [Master]", file: "funds" },
  { name: "Allocators [Master]", file: "allocators" },
];

async function fetchTable(tableName, fileName) {
  let allRecords = [];
  let offset = undefined;

  console.log(`\n‚è≥ Fetching records from table: ${tableName}...`);

  try {
    do {
      const url = ``;
      const response = await axios.get(url, {
        headers: {
          Authorization: `Bearer ${AIRTABLE_PAT}`,
        },
        params: { pageSize: 100, offset },
      });

      allRecords = [...allRecords, ...response.data.records];
      offset = response.data.offset;

    } while (offset);

    console.log(`‚úÖ Retrieved ${allRecords.length} records from "${tableName}".`);

    // Write JSON
    fs.writeFileSync(
      `airtable_${fileName}.json`,
      JSON.stringify(allRecords, null, 2)
    );

    // Write readable TXT
    const readable = allRecords
      .map((rec, index) => `#${index + 1}\nID: ${rec.id}\n${JSON.stringify(rec.fields, null, 2)}\n`)
      .join("\n");

    fs.writeFileSync(`airtable_${fileName}.txt`, readable);

    console.log(`üìÅ Saved -> airtable_${fileName}.json and airtable_${fileName}.txt`);

  } catch (err) {
    console.error(`‚ùå Error fetching table "${tableName}":`);
    console.error(err.response?.data || err.message);
  }
}

async function run() {
  for (const t of TABLES) {
    await fetchTable(t.name, t.file);
  }
  console.log("\n‚ú® Done exporting Airtable data.");
}

run();

so i can run the code with either node airtableService or through a tool.
that means i have to embedd the gotten data to ragie
Step 2: Load data into Ragie
This section will teach you how to load data into Ragie using the data ingest APIs

Suggest Edits
In this section, we will load data into Ragie from a directory that has some files in it. The example files that we are using are available in our ragie-examples GitHub repository. For this example, we will use Ragie's multipart file uploader API, but when you build your application, you ingest data into Ragie using four different methods:

The multipart file uploader API
Uploading files directly using Ragie's CLI
The raw content JSON API
Using a connector to keep data synchronized from a source
Here is some code to accomplish what we just described. It's similar, but not exactly the same as the code in our GitHub repository. For this example, we've removed error handling and some output so we can focus on only the data ingest logic. For a more robust example, see the tutorial in ragie-examples.

Install the Ragie TypeScript client

Shell

npm install ragie
TypeScript

import fs from "fs";
import { readFile } from "node:fs/promises";
import path from "path";
import { Ragie } from "ragie";

const apiKey = "<YOUR API KEY>";
const directory = "path/to/directory";

(async () => {
  const files = fs.readdirSync(directory);
  
  const ragie = new Ragie({
    auth: apiKey
  });
  
  for (const file of files) {
    const filePath = path.join(directory, file);
    const fileContent = await readFile(filePath);
    const blob = new Blob([fileContent]);
  
    const response = await ragie.documents.create({
      file: blob,
      name: file,
      metadata: {
        title: file,
        scope: "tutorial"
      }
    });
  }
})();
Each document in the directory is loaded into Ragie and then processed. The amount of time it takes to process each document can vary based on the type of document that is passed to Ragie as well as the mode in which the document is processed.

After this runs successfully, we will have added all of our podcasts into Ragie. We can then use this data later in our application to generate content which includes data that the LLM model has not been trained on. This is the beauty of RAG and how Ragie helps you build these types of applications quickly.

Using Metadata
Notice that in our example above, we added some metadata to our API call. You can attach metadata to any document that you send to Ragie. Metadata can be used later during retrieval to filter results. Typical usages of metadata include attaching an "scope", "environment" or including an "organization_id" to segment your customer data. Metadata may also include more information about the document that you want to reference in your application such as the title of the document or the source url of the document. What you put in metadata is up to you and your application.
Understanding Mode
Ragie can process documents in different modes depending on the file type. For text documents, choose between 'hi_res' (extracts text, images, and tables) and 'fast' (text-only, much faster). 'hi_res' works with Word, PDF, Images, and PowerPoint files. For audio files, use true/false to enable/disable processing. For video files, choose 'audio_only', 'video_only', or 'audio_video'. When specifying multiple strategies, use a JSON object with keys: "static" for text, "audio" for audio, and "video" for video files. Omitted keys indicate that document type won't be processed.
Querying document status
You may query the document to see if it has been fully processed. When you see a status of ready, the document has been fully processed and is ready to be used in retrieval.

TypeScript

import { Ragie } from "ragie";

const apiKey = "<YOUR API KEY>";
const id = "21881de1-65f7-4816-b571-3ef69661c375";

const ragie = new Ragie({
  auth: apiKey
});

// Retrieve document status
(async () => {
  const document = await ragie.documents.get({
    documentId: id
  });

  console.log(document);
})();
Sample output would looks like this:

JSON

{
  "id": "21881de1-65f7-4816-b571-3ef69661c375",
  "created_at": "2024-07-05T22:21:21.099975Z",
  "updated_at": "2024-07-05T22:21:37.521837Z",
  "status": "ready",
  "name": "All In Pod Episode E112.pdf",
  "metadata": {
    "title": "All In Pod Episode E112.pdf",
    "scope": "tutorial"
  },
  "chunk_count": 86,
  "external_id": null
}
It is typical to poll for the document status to know when a document is ready. Alternatively, Ragie supports webhooks that can push document status changes to your application.

What did Ragie do?
Ragie extracted all of the information from your documents. By default, Ragie uses ‚Äúfast‚Äù mode to extract data. ‚ÄúFast‚Äù mode is perfect for text documents, but will miss some information in complex documents that include images, charts, and tables. Ragie has a ‚Äúhi_res‚Äù mode for processing complex documents that uses a combination of models, such as multi-modal LLMs and OCR, to extract non-textual information. This allows your generative ai applications to use the typically inaccessible information embedded in charts, graphs, and other non-textual content. Keep in mind that there is a speed tradeoff when using ‚Äúfast‚Äù vs ‚Äúhi_res‚Äù modes.
Ragie created optimized chunks from your documents for use in your prompt‚Äôs context window (you‚Äôll see an example of this later in the tutorial). Naive approaches to chunking can be fairly simple, but optimal chunking is a complex and rapidly evolving area of research. Ragie stays at the forefront of this research and implements the most promising techniques.
Ragie indexed the generated chunks for semantic retrieval in a vector search database. This allows your ai applications to perform natural language queries of your data that return the most accurate and relevant information.
Ragie created summaries of your documents and indexed them in a Summary Index, to improve retrieval results. Learn more about the Summary Index.
If you‚Äôve created Entity Extraction Instructions, Ragie may have extracted structured data from your documents. Learn more about Entity Extraction.
Let's recap
In this section, you learned how to:

Use the mulipart document upload API to load data into Ragie. You learned that this is one of three ways that Ragie can ingest data.
Use the document API to query for document status.
Use Ragie for heavy lifting that you would ordinarily need to build yourself. This work is abstracted away from you as a developer so you can focus on building your application.
Updated 5 months ago

Step 1: Create an API key
Step 3: Retrieve Chunks
Did this page help you?
Table of Contents
Querying document status
What did Ragie do?

  